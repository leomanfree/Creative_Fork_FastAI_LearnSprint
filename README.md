# ğŸ§  Creative Fork â€“ Learn Sprint (Fast.ai v22)

This repo documents a 3-day Learn Sprint focused on the Fast.ai 2022 course.

The goal was not just to train a model â€” but to understand the *minimum viable engine* behind it,  
and to reflect on the philosophical structures that underpin machine learning.

---

## ğŸ Project Summary

Over 72 hours, I:

- Built a pet image classifier using Fast.ai
- Fine-tuned the model with transfer learning
- Rebuilt the architecture from scratch in Colab
- Logged all progress and structured the sprint around the Build â†’ Distill â†’ Share loop
- Integrated reflections on classical logic, dialectical thinking, and hybrid human-AI cognition

---

## ğŸ“ Notebooks

- [Day 1 â€“ Build](link-to-day1-notebook)
- [Day 2 â€“ Distill](link-to-day2-notebook)
- [Day 3 â€“ Refine & Reflect](link-to-day3-notebook)

---

## ğŸ” Key Concepts

- Minimum Viable Engine: `DataBlock â†’ Learner â†’ Train â†’ Predict`
- Transfer Learning & `learn.unfreeze()`
- Layer structures and abstraction
- Evaluation via prediction (`learn.predict(img)`)

---

## ğŸ§  Philosophy Blocks

This Learn Sprint also explores foundational ideas behind modern AI:

---

### 1. Aristotelian Structure

> "Each layer performs a logical abstraction â€” from perception to reason."

Layers as **classes of form** (Aristotle, *Posterior Analytics*)  
ML as a continuation of syllogistic reasoning in computational form.

ğŸ“š Ref: Lukasiewicz, *Aristotle's Syllogistic from the Standpoint of Modern Formal Logic*

---

### 2. Hegelian Dialectic & Logical Form

> "Knowledge arises not from repetition, but from contradiction."

Inspired by Hegelâ€™s *Science of Logic*:

- The logic of becoming  
- Contradiction as the motor of development  
- Abstraction through negation  
- Categories as dynamic, not static

Just like in backpropagation:  
â†’ The model learns by negating error, not just reinforcing signal.

ğŸ“š Ref: Hegel, *Science of Logic* (1812â€“16)

---

### 3. Beyond Statistics: Hybrid Intelligence

> "LLMs are brilliant sophists. They optimize for likelihood, not meaning."

Reflections on von Franz, Jung, and the limits of probabilistic inference.  
The future isnâ€™t artificial minds â€” itâ€™s **engineered human-AI cognition.**

From co-pilots to **cognitive stacks**.  
From fine-tuning weights to fine-tuning minds.

ğŸ“š Ref: von Franz, *On Divination and Synchronicity*  
ğŸ“„ Ref: *Self-Reflecting LLMs: A Hegelian Dialectical Approach* (arXiv:2501.14917)

---

## ğŸš€ Closing Thoughts

This sprint was a testbed.  
The repo is live, the model runs, but the real experiment is:

> How far can we stretch the meaning of â€œlearningâ€ â€” with and beyond AI?

DM me if you're exploring the same questions.
